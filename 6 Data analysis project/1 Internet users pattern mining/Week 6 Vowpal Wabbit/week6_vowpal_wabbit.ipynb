{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://habrastorage.org/web/677/8e1/337/6778e1337c3d4b159d7e99df94227cb2.jpg\"/>\n",
    "## Специализация \"Машинное обучение и анализ данных\"\n",
    "</center>\n",
    "<center>Автор материала: программист-исследователь Mail.ru Group, старший преподаватель Факультета Компьютерных Наук ВШЭ Юрий Кашницкий"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Capstone проект №1. Идентификация пользователей по посещенным веб-страницам\n",
    "<img src='http://i.istockimg.com/file_thumbview_approve/21546327/5/stock-illustration-21546327-identification-de-l-utilisateur.jpg'>\n",
    "\n",
    "# <center>Неделя 6.  Vowpal Wabbit\n",
    "\n",
    "На этой неделе мы познакомимся с популярной библиотекой Vowpal Wabbit и попробуем ее на данных соревнования. Знакомиться будем на [данных](http://scikit-learn.org/stable/datasets/twenty_newsgroups.html) Scikit-learn по новостям, сначала в режиме бинарной классификации, затем – в многоклассовом режиме. Затем будем классифицировать рецензии к фильмам с сайта IMDB. Наконец, применим Vowpal Wabbit к данным по веб-сессиям. Материала немало, но Vowpal Wabbit того стоит!\n",
    "\n",
    "**План 6 недели:**\n",
    "- Часть 1. Статья по Vowpal Wabbit\n",
    "- Часть 2. Применение Vowpal Wabbit к данным по посещению сайтов\n",
    " - 2.1. Подготовка данных\n",
    " - 2.2. Валидация по отложенной выборке\n",
    " - 2.3. Валидация по тестовой выборке (Public Leaderboard)\n",
    "\n",
    "**В этой части проекта Вам могут быть полезны видеозаписи следующих лекций курса \"Обучение на размеченных данных\":**\n",
    "   - [Стохатический градиентный спуск](https://www.coursera.org/learn/supervised-learning/lecture/xRY50/stokhastichieskii-ghradiientnyi-spusk)\n",
    "   - [Линейные модели. Sklearn.linear_model. Классификация](https://www.coursera.org/learn/supervised-learning/lecture/EBg9t/linieinyie-modieli-sklearn-linear-model-klassifikatsiia)\n",
    "   \n",
    "Также будет полезна [презентация](https://github.com/esokolov/ml-course-msu/blob/master/ML15/lecture-notes/Sem08_vw.pdf) лектора специализации Евгения Соколова. И, конечно же, [документация](https://github.com/JohnLangford/vowpal_wabbit/wiki) Vowpal Wabbit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Статья про Vowpal Wabbit\n",
    "Прочитайте [статью](https://habrahabr.ru/company/ods/blog/326418/) про Vowpal Wabbit на Хабре из серии открытого курса OpenDataScience по машинному обучению. Материал для этой статьи зародился из нашей специализации. Скачайте [тетрадку](https://github.com/Yorko/mlcourse_open/blob/master/jupyter_notebooks/topic08_sgd_hashing_vowpal_wabbit/topic8_sgd_hashing_vowpal_wabbit.ipynb), прилагаемую к статье, посмотрите код, изучите его, поменяйте, только так можно разобраться с Vowpal Wabbit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. Применение Vowpal Wabbit к данным по посещению сайтов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Далее посмотрим на Vowpal Wabbit в деле. Правда, в задаче нашего соревнования при бинарной классификации веб-сессий мы разницы не заметим – как по качеству, так и по скорости работы (хотя можете проверить), продемонстрируем всю резвость VW в задаче классификации на 400 классов. Исходные данные все те же самые, но выделено 400 пользователей, и решается задача их идентификации. Скачайте данные [отсюда](https://inclass.kaggle.com/c/identify-me-if-you-can4/data) – файлы `train_sessions_400users.csv` и `test_sessions_400users.csv`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Поменяйте на свой путь к данным\n",
    "PATH_TO_DATA = ('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Загрузим обучающую и тестовую выборки. Можете заметить, что тестовые сессии здесь по времени четко отделены от сессий в обучающей выборке. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_400 = pd.read_csv(os.path.join(PATH_TO_DATA,'train_sessions_400users.csv'), \n",
    "                           index_col='session_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df_400 = pd.read_csv(os.path.join(PATH_TO_DATA,'test_sessions_400users.csv'), \n",
    "                           index_col='session_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>time1</th>\n",
       "      <th>site2</th>\n",
       "      <th>time2</th>\n",
       "      <th>site3</th>\n",
       "      <th>time3</th>\n",
       "      <th>site4</th>\n",
       "      <th>time4</th>\n",
       "      <th>site5</th>\n",
       "      <th>time5</th>\n",
       "      <th>...</th>\n",
       "      <th>time6</th>\n",
       "      <th>site7</th>\n",
       "      <th>time7</th>\n",
       "      <th>site8</th>\n",
       "      <th>time8</th>\n",
       "      <th>site9</th>\n",
       "      <th>time9</th>\n",
       "      <th>site10</th>\n",
       "      <th>time10</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23713</td>\n",
       "      <td>2014-03-24 15:22:40</td>\n",
       "      <td>23720.0</td>\n",
       "      <td>2014-03-24 15:22:48</td>\n",
       "      <td>23713.0</td>\n",
       "      <td>2014-03-24 15:22:48</td>\n",
       "      <td>23713.0</td>\n",
       "      <td>2014-03-24 15:22:54</td>\n",
       "      <td>23720.0</td>\n",
       "      <td>2014-03-24 15:22:54</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-03-24 15:22:55</td>\n",
       "      <td>23713.0</td>\n",
       "      <td>2014-03-24 15:23:01</td>\n",
       "      <td>23713.0</td>\n",
       "      <td>2014-03-24 15:23:03</td>\n",
       "      <td>23713.0</td>\n",
       "      <td>2014-03-24 15:23:04</td>\n",
       "      <td>23713.0</td>\n",
       "      <td>2014-03-24 15:23:05</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8726</td>\n",
       "      <td>2014-04-17 14:25:58</td>\n",
       "      <td>8725.0</td>\n",
       "      <td>2014-04-17 14:25:59</td>\n",
       "      <td>665.0</td>\n",
       "      <td>2014-04-17 14:25:59</td>\n",
       "      <td>8727.0</td>\n",
       "      <td>2014-04-17 14:25:59</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2014-04-17 14:25:59</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-04-17 14:26:01</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2014-04-17 14:26:01</td>\n",
       "      <td>5320.0</td>\n",
       "      <td>2014-04-17 14:26:18</td>\n",
       "      <td>5320.0</td>\n",
       "      <td>2014-04-17 14:26:47</td>\n",
       "      <td>5320.0</td>\n",
       "      <td>2014-04-17 14:26:48</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>303</td>\n",
       "      <td>2014-03-21 10:12:24</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2014-03-21 10:12:36</td>\n",
       "      <td>303.0</td>\n",
       "      <td>2014-03-21 10:12:54</td>\n",
       "      <td>303.0</td>\n",
       "      <td>2014-03-21 10:13:01</td>\n",
       "      <td>303.0</td>\n",
       "      <td>2014-03-21 10:13:24</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-03-21 10:13:36</td>\n",
       "      <td>303.0</td>\n",
       "      <td>2014-03-21 10:13:54</td>\n",
       "      <td>309.0</td>\n",
       "      <td>2014-03-21 10:14:01</td>\n",
       "      <td>303.0</td>\n",
       "      <td>2014-03-21 10:14:06</td>\n",
       "      <td>303.0</td>\n",
       "      <td>2014-03-21 10:14:24</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1359</td>\n",
       "      <td>2013-12-13 09:52:28</td>\n",
       "      <td>925.0</td>\n",
       "      <td>2013-12-13 09:54:34</td>\n",
       "      <td>1240.0</td>\n",
       "      <td>2013-12-13 09:54:34</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>2013-12-13 09:54:34</td>\n",
       "      <td>1344.0</td>\n",
       "      <td>2013-12-13 09:54:34</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-12-13 09:54:34</td>\n",
       "      <td>1346.0</td>\n",
       "      <td>2013-12-13 09:54:34</td>\n",
       "      <td>1345.0</td>\n",
       "      <td>2013-12-13 09:54:34</td>\n",
       "      <td>1344.0</td>\n",
       "      <td>2013-12-13 09:58:19</td>\n",
       "      <td>1345.0</td>\n",
       "      <td>2013-12-13 09:58:19</td>\n",
       "      <td>601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>2013-11-26 12:35:29</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2013-11-26 12:35:31</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2013-11-26 12:35:31</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2013-11-26 12:35:32</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2013-11-26 12:35:32</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-11-26 12:35:32</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2013-11-26 12:37:03</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2013-11-26 12:37:03</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2013-11-26 12:37:03</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2013-11-26 12:37:04</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1                time1    site2                time2    site3  \\\n",
       "session_id                                                                      \n",
       "1           23713  2014-03-24 15:22:40  23720.0  2014-03-24 15:22:48  23713.0   \n",
       "2            8726  2014-04-17 14:25:58   8725.0  2014-04-17 14:25:59    665.0   \n",
       "3             303  2014-03-21 10:12:24     19.0  2014-03-21 10:12:36    303.0   \n",
       "4            1359  2013-12-13 09:52:28    925.0  2013-12-13 09:54:34   1240.0   \n",
       "5              11  2013-11-26 12:35:29     85.0  2013-11-26 12:35:31     52.0   \n",
       "\n",
       "                          time3    site4                time4    site5  \\\n",
       "session_id                                                               \n",
       "1           2014-03-24 15:22:48  23713.0  2014-03-24 15:22:54  23720.0   \n",
       "2           2014-04-17 14:25:59   8727.0  2014-04-17 14:25:59     45.0   \n",
       "3           2014-03-21 10:12:54    303.0  2014-03-21 10:13:01    303.0   \n",
       "4           2013-12-13 09:54:34   1360.0  2013-12-13 09:54:34   1344.0   \n",
       "5           2013-11-26 12:35:31     85.0  2013-11-26 12:35:32     11.0   \n",
       "\n",
       "                          time5   ...                  time6    site7  \\\n",
       "session_id                        ...                                   \n",
       "1           2014-03-24 15:22:54   ...    2014-03-24 15:22:55  23713.0   \n",
       "2           2014-04-17 14:25:59   ...    2014-04-17 14:26:01     45.0   \n",
       "3           2014-03-21 10:13:24   ...    2014-03-21 10:13:36    303.0   \n",
       "4           2013-12-13 09:54:34   ...    2013-12-13 09:54:34   1346.0   \n",
       "5           2013-11-26 12:35:32   ...    2013-11-26 12:35:32     11.0   \n",
       "\n",
       "                          time7    site8                time8    site9  \\\n",
       "session_id                                                               \n",
       "1           2014-03-24 15:23:01  23713.0  2014-03-24 15:23:03  23713.0   \n",
       "2           2014-04-17 14:26:01   5320.0  2014-04-17 14:26:18   5320.0   \n",
       "3           2014-03-21 10:13:54    309.0  2014-03-21 10:14:01    303.0   \n",
       "4           2013-12-13 09:54:34   1345.0  2013-12-13 09:54:34   1344.0   \n",
       "5           2013-11-26 12:37:03     85.0  2013-11-26 12:37:03     10.0   \n",
       "\n",
       "                          time9   site10               time10 user_id  \n",
       "session_id                                                             \n",
       "1           2014-03-24 15:23:04  23713.0  2014-03-24 15:23:05     653  \n",
       "2           2014-04-17 14:26:47   5320.0  2014-04-17 14:26:48     198  \n",
       "3           2014-03-21 10:14:06    303.0  2014-03-21 10:14:24      34  \n",
       "4           2013-12-13 09:58:19   1345.0  2013-12-13 09:58:19     601  \n",
       "5           2013-11-26 12:37:03     85.0  2013-11-26 12:37:04     273  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_400.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 182793 entries, 1 to 182793\n",
      "Data columns (total 21 columns):\n",
      "site1      182793 non-null int64\n",
      "time1      182793 non-null object\n",
      "site2      181175 non-null float64\n",
      "time2      181175 non-null object\n",
      "site3      179441 non-null float64\n",
      "time3      179441 non-null object\n",
      "site4      178054 non-null float64\n",
      "time4      178054 non-null object\n",
      "site5      176653 non-null float64\n",
      "time5      176653 non-null object\n",
      "site6      175268 non-null float64\n",
      "time6      175268 non-null object\n",
      "site7      173960 non-null float64\n",
      "time7      173960 non-null object\n",
      "site8      172738 non-null float64\n",
      "time8      172738 non-null object\n",
      "site9      171437 non-null float64\n",
      "time9      171437 non-null object\n",
      "site10     170247 non-null float64\n",
      "time10     170247 non-null object\n",
      "user_id    182793 non-null int64\n",
      "dtypes: float64(9), int64(2), object(10)\n",
      "memory usage: 30.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df_400.info(null_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Видим, что в обучающей выборке 182793 сессий, в тестовой – 46473, и сессии действительно принадлежат 400 различным пользователям.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((182793, 21), (46473, 20), 400)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_400.shape, test_df_400.shape, train_df_400['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vowpal Wabbit любит, чтоб метки классов были распределены от 1 до K, где K – число классов в задаче классификации (в нашем случае – 400). Поэтому придется применить `LabelEncoder`, да еще и +1 потом добавить (`LabelEncoder` переводит метки в диапозон от 0 до K-1). Потом надо будет применить обратное преобразование.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train_df_400['user_id']\n",
    "class_encoder = LabelEncoder()\n",
    "y_for_vw = class_encoder.fit_transform(y) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Далее будем сравнивать VW с SGDClassifier и с логистической регрессией. Всем этим моделям нужна предобработка входных данных. Подготовьте для sklearn-моделей разреженные матрицы, как мы это делали в 5 части:**\n",
    "- объедините обучающую и тестовую выборки\n",
    "- выберите только сайты (признаки от 'site1' до 'site10')\n",
    "- замените пропуски на нули (сайты у нас нумеровались с 0)\n",
    "- переведите в разреженный формат `csr_matrix`\n",
    "- разбейте обратно на обучающую и тестовую части"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dropcols_coo(C, idx_to_drop):\n",
    "    idx_to_drop = np.unique(idx_to_drop)\n",
    "    keep = ~np.in1d(C.col, idx_to_drop)\n",
    "    C.data, C.row, C.col = C.data[keep], C.row[keep], C.col[keep]\n",
    "    C.col -= idx_to_drop.searchsorted(C.col)    # decrement column indices\n",
    "    C._shape = (C.shape[0], C.shape[1] - len(idx_to_drop))\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_to_csr_matrix(arr):\n",
    "    rows = []\n",
    "    columns = []\n",
    "    data = []\n",
    "    for i in range(arr.shape[0]):\n",
    "        # Create dictionary {site: number of visits per session}\n",
    "        unique, counts = np.unique(arr[i], return_counts=True)\n",
    "        dic = dict(zip(unique, counts))\n",
    "        rows.extend([i]*len(dic.keys()))\n",
    "        columns.extend(dic.keys())\n",
    "        data.extend(dic.values())\n",
    "    \n",
    "    # Sparse coo matrix\n",
    "    arr_new_coo = coo_matrix((data, (rows, columns)))\n",
    "    \n",
    "    # Drop column with \"zero\" site and transform to csr\n",
    "    return dropcols_coo(arr_new_coo, 0).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sites = ['site' + str(i) for i in range(1, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test_df = pd.concat([train_df_400, test_df_400])\n",
    "train_test_df_sites = train_test_df[sites].fillna(0).astype('int')\n",
    "train_test_sparse = transform_to_csr_matrix(train_test_df_sites.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sparse = train_test_sparse[:train_df.shape[0]]\n",
    "X_test_sparse = train_test_sparse[train_df.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182793, 36656)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sparse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46473, 36656)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_sparse.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Валидация по отложенной выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выделим обучающую (70%) и отложенную (30%) части исходной обучающей выборки. Данные не перемешиваем, учитываем, что сессии отсортированы по времени.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = train_df_400[sites].fillna(0).astype(np.int32)\n",
    "test_df = test_df_400[sites].fillna(0).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_share = int(.7 * train_df_400.shape[0])\n",
    "train_df_part = train_df_400[sites].iloc[:train_share, :].fillna(0).astype(np.int32)\n",
    "valid_df = train_df_400[sites].iloc[train_share:, :].fillna(0).astype(np.int32)\n",
    "X_train_part_sparse = X_train_sparse[:train_share, :]\n",
    "X_valid_sparse = X_train_sparse[train_share:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_part = y[:train_share]\n",
    "y_valid = y[train_share:]\n",
    "y_train_part_for_vw = y_for_vw[:train_share]\n",
    "y_valid_for_vw = y_for_vw[train_share:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Реализуйте функцию, `arrays_to_vw`, переводящую обучающую выборку в формат Vowpal Wabbit.**\n",
    "\n",
    "Вход:\n",
    " - X – матрица `NumPy` (обучающая выборка)\n",
    " - y (необяз.) - вектор ответов (`NumPy`). Необязателен, поскольку тестовую матрицу будем обрабатывать этой же функцией\n",
    " - train – флаг, True в случае обучающей выборки, False – в случае тестовой выборки\n",
    " - out_file – путь к файлу .vw, в который будет произведена запись\n",
    " \n",
    "Детали:\n",
    "- надо пройтись по всем строкам матрицы `X` и записать через пробел все значения, предварительно добавив вперед нужную метку класса из вектора `y` и знак-разделитель `|`\n",
    "- в тестовой выборке на месте меток целевого класса можно писать произвольные, допустим, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def arrays_to_vw(X, y=None, train=True, out_file='tmp.vw'):\n",
    "    with open(os.path.join(PATH_TO_DATA, out_file), 'w') as out_vw:\n",
    "        for i, row in enumerate(np.nditer(X, flags=['external_loop'], order='C')):\n",
    "            arr_str = ' '.join(list(map(str, row)))\n",
    "            if y is None:\n",
    "                label = 1\n",
    "            else:\n",
    "                label = y[i]\n",
    "            vw_str = '{} | {}'.format(label, arr_str)\n",
    "            out_vw.write(vw_str + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примените написанную функцию к части обучащей выборки `(train_df_part, y_train_part_for_vw)`, к отложенной выборке `(valid_df, y_valid_for_vw)`, ко всей обучающей выборке и ко всей тестовой выборке. Обратите внимание, что на вход наш метод принимает именно матрицы и вектора `NumPy`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.5 s, sys: 47.8 ms, total: 12.6 s\n",
      "Wall time: 12.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "arrays_to_vw(train_df_part.values, y_train_part_for_vw, out_file='train_part.vw')\n",
    "arrays_to_vw(valid_df.values, y_valid_for_vw, out_file='valid.vw')\n",
    "arrays_to_vw(train_df.values, y_for_vw, out_file='train.vw')\n",
    "arrays_to_vw(test_df.values, out_file='test.vw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Результат должен получиться таким.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262 | 23713 23720 23713 23713 23720 23713 23713 23713 23713 23713\r\n",
      "82 | 8726 8725 665 8727 45 8725 45 5320 5320 5320\r\n",
      "16 | 303 19 303 303 303 303 303 309 303 303\r\n"
     ]
    }
   ],
   "source": [
    "!head -3 $PATH_TO_DATA/train_part.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 | 7 923 923 923 11 924 7 924 838 7\r\n",
      "160 | 91 198 11 11 302 91 668 311 310 91\r\n",
      "312 | 27085 848 118 118 118 118 11 118 118 118\r\n"
     ]
    }
   ],
   "source": [
    "!head -3  $PATH_TO_DATA/valid.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 | 9 304 308 307 91 308 312 300 305 309\r\n",
      "1 | 838 504 68 11 838 11 838 886 27 305\r\n",
      "1 | 190 192 8 189 191 189 190 2375 192 8\r\n"
     ]
    }
   ],
   "source": [
    "!head -3 $PATH_TO_DATA/test.vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучите модель Vowpal Wabbit на выборке `train_part.vw`. Укажите, что решается задача классификации с 400 классами (`--oaa`), сделайте 3 прохода по выборке (`--passes`). Задайте некоторый кэш-файл (`--cache_file`, можно просто указать флаг `-c`), так VW будет быстрее делать все следующие после первого проходы по выборке (прошлый кэш-файл удаляется с помощью аргумента `-k`). Также укажите значение параметра `b`=26. Это число бит, используемых для хэширования, в данном случае нужно больше, чем 18 по умолчанию. Наконец, укажите `random_seed`=17. Остальные параметры пока не меняйте, далее уже в свободном режиме соревнования можете попробовать другие функции потерь.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_part_vw = os.path.join(PATH_TO_DATA, 'train_part.vw')\n",
    "valid_vw = os.path.join(PATH_TO_DATA, 'valid.vw')\n",
    "train_vw = os.path.join(PATH_TO_DATA, 'train.vw')\n",
    "test_vw = os.path.join(PATH_TO_DATA, 'test.vw')\n",
    "model = os.path.join(PATH_TO_DATA, 'vw_model.vw')\n",
    "pred = os.path.join(PATH_TO_DATA, 'vw_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 581 ms, sys: 108 ms, total: 689 ms\n",
      "Wall time: 27.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!vw -d data/train_part.vw \\\n",
    "--passes 3 \\\n",
    "--oaa 400 \\\n",
    "-c \\\n",
    "-k \\\n",
    "-b 26 \\\n",
    "--random_seed 17 \\\n",
    "-f data/model.vw \\\n",
    "--quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Запишите прогнозы на выборке *valid.vw* в *vw_valid_pred.csv*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.1 ms, sys: 35.7 ms, total: 78.8 ms\n",
      "Wall time: 2.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!vw -i data/model.vw -t -d data/valid.vw \\\n",
    "-p vw_valid_pred.txt \\\n",
    "--quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Считайте прогнозы *data/vw_valid_pred.csv*  из файла и посмотрите на долю правильных ответов на отложенной части.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34541741128414605"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('vw_valid_pred.txt') as pred_file:\n",
    "    valid_prediction = [int(label) for label in pred_file.readlines()]\n",
    "    \n",
    "accuracy_score(y_valid_for_vw, valid_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4, 160, 312, ..., 254,  91, 256])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid_for_vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([188, 220, 364, ..., 118, 318, 125])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(valid_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Теперь обучите `SGDClassifier` (3 прохода по выборке, логистическая функция потерь) и `LogisticRegression` на 70% разреженной обучающей выборки – `(X_train_part_sparse, y_train_part)`, сделайте прогноз для отложенной выборки `(X_valid_sparse, y_valid)` и посчитайте доли верных ответов. Логистическая регрессия будет обучаться долго (у меня – 15 минут) – это нормально. Укажите везде `random_state`=17, `n_jobs`=-1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logit = LogisticRegression(random_state=17, n_jobs=-1)\n",
    "sgd_logit = SGDClassifier(loss='log', max_iter=3, random_state=17, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxis/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43min 37s, sys: 15.7 s, total: 43min 53s\n",
      "Wall time: 21min 57s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "          penalty='l2', random_state=17, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "logit.fit(X_train_part_sparse, y_train_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 23s, sys: 21.2 s, total: 1min 44s\n",
      "Wall time: 27.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=3, n_iter=None,\n",
       "       n_jobs=-1, penalty='l2', power_t=0.5, random_state=17, shuffle=True,\n",
       "       tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "sgd_logit.fit(X_train_part_sparse, y_train_part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какими получаются доли правильных ответов на отложенной выборке для Vowpal Wabbit, SGD и логистической регрессии? Запишите 3 числа в файл *answer6_1.txt* (в указанном порядке, сначала VW, потом SGD и logit) через пробел, округлив до 3 знаков после запятой.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "vw_valid_acc = accuracy_score(y_valid_for_vw, valid_prediction)\n",
    "sgd_valid_acc = accuracy_score(y_valid, sgd_logit.predict(X_valid_sparse))\n",
    "logit_valid_acc = accuracy_score(y_valid, logit.predict(X_valid_sparse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_answer_to_file(answer, file_address):\n",
    "    with open(file_address, 'w') as out_f:\n",
    "        out_f.write(str(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_answer_to_file(\"{}  {} {}\".format(round(vw_valid_acc, 3), round(sgd_valid_acc, 3),\n",
    "                                     round(logit_valid_acc, 3)),  \n",
    "                     'answer6_1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3. Валидация по тестовой выборке (Public Leaderboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучите модель VW с теми же параметрами на всей обучающей выборке – *train.vw*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 829 ms, sys: 89.2 ms, total: 919 ms\n",
      "Wall time: 35.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!vw -d data/train.vw \\\n",
    "--passes 3 \\\n",
    "--oaa 400 \\\n",
    "-c \\\n",
    "-k \\\n",
    "-b 26 \\\n",
    "--random_seed 17 \\\n",
    "-f data/model.vw \\\n",
    "--quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сделайте прогноз для тестовой выборки.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.5 ms, sys: 28 ms, total: 69.5 ms\n",
      "Wall time: 1.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!vw -i data/model.vw -t -d data/test.vw \\\n",
    "-p vw_test_pred.txt \\\n",
    "--quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('vw_test_pred.txt') as pred_file:\n",
    "    vw_pred = np.array([int(label) for label in pred_file.readlines()])\n",
    "    \n",
    "vw_pred = class_encoder.inverse_transform(vw_pred - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Запишите прогноз в файл, примените обратное преобразование меток (был LabelEncoder и потом +1 в меткам) и отправьте решение на Kaggle.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_submission_file(predicted_labels, out_file,\n",
    "                             target='user_id', index_label=\"session_id\"):\n",
    "    # turn predictions into data frame and save as csv file\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = np.arange(1, predicted_labels.shape[0] + 1),\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_submission_file(vw_pred, os.path.join(PATH_TO_DATA, 'vw_400_users.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сделайте то же самое для SGD и логистической регрессии. Тут уже ждать обучение логистической регрессии совсем скучно (заново запускать тетрадку вам не захочется), но давайте дождемся.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logit = LogisticRegression(random_state=17, n_jobs=-1)\n",
    "sgd_logit = SGDClassifier(loss='log', max_iter=3, random_state=17, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxis/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 11min 11s, sys: 23.1 s, total: 1h 11min 34s\n",
      "Wall time: 35min 47s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "          penalty='l2', random_state=17, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "logit.fit(X_train_sparse, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 55s, sys: 21.3 s, total: 2min 16s\n",
      "Wall time: 34.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=3, n_iter=None,\n",
       "       n_jobs=-1, penalty='l2', power_t=0.5, random_state=17, shuffle=True,\n",
       "       tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "sgd_logit.fit(X_train_sparse, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_test_pred = logit.predict(X_test_sparse)\n",
    "sgd_logit_test_pred = sgd_logit.predict(X_test_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_submission_file(logit_test_pred, \n",
    "                         os.path.join(PATH_TO_DATA, 'logit_400_users.csv'))\n",
    "write_to_submission_file(sgd_logit_test_pred, \n",
    "                         os.path.join(PATH_TO_DATA, 'sgd_400_users.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какими получаются доли правильных ответов  Vowpal Wabbit, SGD и логистической регрессии на публичной части (public leaderboard) тестовой выборки [этого](https://inclass.kaggle.com/c/identify-me-if-you-can4) соревнования? Запишите 3 числа в файл *answer6_2.txt* (в указанном порядке, сначала VW, потом SGD и logit) через пробел, округлив до 3 знаков после запятой.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_answer_to_file(' '.join(map(str, [0.188, 0.175, 0.199])), 'answer6_2.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**В заключение по заданию:**\n",
    "- Про соотношение качества классификации и скорости обучения VW, SGD и logit выводы предлагается сделать самостоятельно\n",
    "- Пожалуй, задача классификации на 400 классов (идентификация 400 пользователей) решается недостаточно хорошо при честном отделении по времени тестовой выборки от обучающей. Далее мы будем соревноваться в идентификации одного пользователя (Элис) – [вот](https://inclass.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2) соревнование, в котором предлагается поучаствовать и описать результаты в проекте. Не перепутайте! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пути улучшения\n",
    "\n",
    "Что еще можно попробовать в [соревновании](https://inclass.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2):\n",
    " - Использовать ранее построенные признаки для улучшения модели\n",
    " - Настроить параметры Vowpal Wabbit с hyperopt\n",
    " - Попробовать TF-IDF и n-граммы\n",
    "\n",
    "На следующей, заключительной, неделе мы оформим всю работу над проектом в виде одного файла (`html`, `pdf` или `ipynb`) и будем проверять проекты друг друга."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
